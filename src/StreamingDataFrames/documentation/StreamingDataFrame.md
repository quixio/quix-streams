
# `StreamingDataFrame`: Detailed Overview

Now that we've outlined how to get an `Application` up and running, what exactly can you
do with a `StreamingDataFrame`?

<br>

For example purposes, assume the record we are manipulating looks like this:

```python
row = {
    "field_a": "my_str", 
    "field_b": "my_other_str",
    "field_c": [1, 2, 3],
    "field_d": "DELETE ME",
}
```

Along with a `StreamingDataFrame` instance, as generated by an `Application`:

```python
sdf = Application().dataframe()
```

<br>

## Interacting with `Rows`

Under the hood, `StreamingDataFrame` is manipulating kafka messages via `Row` objects.

Simplified, a `Row` is effectively a dictionary of the Kafka message 
value, with each key equivalent to a dataframe column name. 

Our `StreamingDataFrame` interacts with `Row` objects via the Pandas dataframe
interface, unless specified otherwise (i.e. the `.apply()` feature).

As a user, their existence should largely go unnoticed.


<br>

## Accessing Fields/Columns

In typical Pandas dataframe fashion, you can access a column:

```python
sdf["field_a"]  # "my_str"
```

Typically, this is done in combination with other operations.

You can also access nested objects (dicts, lists, etc):

```python
sdf["field_c"][2]  # 3
```


<br>

## Performing Operations with Columns

In typical Pandas dataframe fashion, you can do almost any basic operations or 
comparisons with columns, assuming validity:

```python
sdf["field_a"] + sdf["field_b"]
sdf["field_a"] or sdf["field_b"]
sdf["field_a"] & sdf["field_b"]
sdf["field_a"] is not None
sdf["field_a"] != "woo"
```


<br>

## Assigning New Columns

In typical Pandas fashion, you can add new columns from the results of numerous other
operations:

```python
sdf["a_new_int_field"] = 5 
sdf["a_new_str_field"] = sdf["field_a"] + sdf["field_b"]
sdf["another_new_field"] = sdf["a_new_str_field"].apply(lambda value: value + "another")
```

See [the `.apply()` section](#user-defined-functions-apply) for more information on how that works.


<br>

## Subsetting/Slicing Columns

In typical Pandas fashion, you can take a subset of columns:

```python
# remove "field_d"
sdf = sdf[["field_a", "field_b", "field_c"]]
```


<br>

## Filtering Rows (messages)

"Filtering" is a very specific concept and operation with `StreamingDataFrames`.

In practice, it functions similarly to how you might filter rows with Pandas DataFrames
with conditionals.

Basically, when a "column" reference is actually another operation, it will be treated 
as a "filter". If that result is empty or None, the row is now "filtered".

When filtered, ALL additional SDF-defined processes for that row are now skipped,
_including kafka-related operations like producing_.

```python
# This would continue onward
sdf = sdf[sdf["field_a"] == "my_str"]

# This would filter the row, skipping further functions
sdf = sdf[(sdf["field_a"] != "woo") and (sdf["field_c"][0] > 100)]
```

<br>

## User Defined Functions: `.apply()`

Should you need more advanced transformations, `.apply()` allows you
to use any python function to operate on your row.

When used on a `StreamingDataFrame`, your function must accept 2 ordered arguments, 
first is the row data (as a dictionary), and the other is a special "context" object
that allows you to access other message metadata (key, partition, etc).

Consequently, your function **MUST either** _alter this dict in-place_ 
**OR** _return a dictionary_ to directly replace the current data with.

For example:

```python
# in place example
def in_place(row, ctx):
    for k in list(row.keys()):
        if isinstance(row[k], str):
            del row[k]     
            
sdf = sdf.apply(in_place)


# replacement example
def new_data(row, ctx):
    return {col: val for col, val in row.items() if isinstance(val, str)}

sdf = sdf.apply(new_data)
```

<br>

The `.apply()` function is also valid for columns, but rather than providing a 
dictionary, it instead uses the column value, and the function must return a value.

```python
sdf["new_field"] = sdf["field_a"].apply(lambda value: value + "-add_me")
```

NOTE: Every `.apply()` is a _temporary_ state change, but the result can be assigned. 
So, in the above example, `field_a` remains `my_str`, but `new_field == my_str-add_me` 
as desired.

<br>

### Stateful Processing with `.apply()`

If you are using stateful processing, you can access the state for a given row via
a keyword argument `stateful=True`, and your function should accept a third object as
an argument (you can just call it something like `state`).

When your function has access to state, it will receive a `State` object, which can do:
- `.get(key)`
- `.set(key, value)`
- `.delete(key)`
- `.exists(key)`

`Key` and value can be anything, and you can have any number of keys.

NOTE: `key` is unrelated to the Kafka message key, which is handled behind the scenes.

```python
def edit_data(row, ctx, state):
    msg_max = len(row["field_c"])
    current_max = state.get("current_len_max")
    if current_max < msg_max:
        state.set("current_len_max", msg_max)
        current_max = msg_max
    row["len_max"] = current_max
    return row


sdf = sdf.apply(edit_data, stateful=True)
```

For more information about stateful processing in general, see 
[**Stateful Applications**](./stateful_processing.md).


<br>

## Producing to Topics: `.to_topic()`

To send the current state of the `StreamingDataFrame` to a topic, simply call 
`to_topic` with a `Topic` instance (like one generated from `Application.topic()`) 
as an argument.

To change the outgoing message key (which defaults to the current consumed key), 
you can optionally provide a key function, which operates similarly to the `.apply()` 
function with a `row` (dict) and `ctx` argument, and returns a desired 
(serializable) key.

```python
output_topic = Application().topic("my_output_topic")
other_output_topic = Application().topic("my_other_output_topic")

def key_generator(row, ctx):
    # do stuff
    return "my_new_key"


### previous sdf stuff here
sdf = sdf.to_topic(output_topic, key=key_generator)

### additional sdf stuff here
sdf = sdf.to_topic(other_output_topic)
```
