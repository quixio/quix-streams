from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional

from quixstreams.core.stream import Stream, VoidExecutor
from quixstreams.models import Topic

from .exceptions import (
    GroupByDuplicate,
    GroupByNestingLimit,
    StreamingDataFrameDuplicate,
)

if TYPE_CHECKING:
    from .dataframe import StreamingDataFrame


class DataframeRegistry:
    """
    Helps manage multiple `StreamingDataFrames` (multi-topic `Applications`)
    and their respective repartitions.

    `SDF`s are registered by storing their topic and current Stream.
    """

    def __init__(self):
        self._registry: Dict[str, Stream] = {}
        self._topics: List[Topic] = []
        # {repartition_topic_name: source_topic_name}
        self._repartition_origins: Dict[str, str] = {}

    @property
    def consumer_topics(self) -> List[Topic]:
        """
        :return: a list of Topics a consumer should subscribe to.
        """
        return self._topics

    def register_root(
        self,
        new_sdf: "StreamingDataFrame",
    ):
        """
        Register a "root" SDF, or the start of a topic's processing.
        :param new_sdf: the new SDF.
        """
        if (topic := new_sdf.topic).name in self._registry:
            raise StreamingDataFrameDuplicate(
                f"There is already a StreamingDataFrame using topic {topic.name}"
            )
        self._topics.append(topic)
        self._registry[topic.name] = new_sdf.stream

    def register_groupby(
        self, source_sdf: "StreamingDataFrame", new_sdf: "StreamingDataFrame"
    ):
        """
        Register a "groupby" SDF, which is one generated with `SDF.group_by()`.
        :param source_sdf: the SDF used by `sdf.group_by()`
        :param new_sdf: the SDF generated by `sdf.group_by()`.
        """
        source_topic = source_sdf.topic.name
        if self._repartition_origins.get(source_topic):
            raise GroupByNestingLimit(
                "Subsequent (nested) `SDF.group_by()` operations are not allowed."
            )
        try:
            self.register_root(new_sdf)
        except StreamingDataFrameDuplicate:
            raise GroupByDuplicate(
                "A `SDF.group_by()` operation appears to be the same as another, "
                "either from using the same column or name parameter; "
                "adjust by setting a unique name with `SDF.group_by(name=<NAME>)` "
            )
        self._repartition_origins[new_sdf.topic.name] = source_topic

    def compose_all(
        self, sink: Optional[Callable[[Any, Any, int, Any], None]] = None
    ) -> Dict[str, VoidExecutor]:
        """
        Composes all the Streams and returns them in a dict, where key is its topic.
        :param sink: callable to accumulate the results of the execution, optional.
        :return: a {topic_name: composed} dict, where composed is a callable
        """
        return {
            topic: stream.compose(sink=sink) for topic, stream in self._registry.items()
        }
